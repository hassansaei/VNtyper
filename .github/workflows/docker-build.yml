# This workflow is run as part of CI to test that they run through.
#
# The images are pushed to `ghcr.io` and 'docker hub' for each PR and branch.  The ones for
# the releases are pushed in `release-please.yml`.
name: Docker Build

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:  # Allow manual trigger

env:
  GHCR_REGISTRY: ghcr.io
  DOCKERHUB_REGISTRY: docker.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push-image:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write  # Required for ghcr.io

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # Set up Docker Buildx (required for caching)
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Log in to GitHub Container Registry (ghcr.io)
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.GHCR_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Log in to Docker Hub
      #- name: Log in to Docker Hub
        #uses: docker/login-action@v3
        #with:
          #registry: ${{ env.DOCKERHUB_REGISTRY }}
          #username: ${{ secrets.DOCKER_USERNAME }}  # Added to GitHub secrets
          #password: ${{ secrets.DOCKER_PASSWORD }}  # Added to GitHub secrets

      # Extract metadata (tags, labels) for Docker
      - name: Extract metadata (tags, labels) for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            ${{ env.GHCR_REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=schedule
            type=ref,event=branch
            type=ref,event=tag
            type=ref,event=pr
            type=sha

      # Build and push Docker image to both registries
      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: docker/Dockerfile
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          push: true
          # Enable GitHub Actions caching for 60-80% faster builds
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Docker Quick Tests - Run on all PRs for fast feedback
  test-docker-quick:
    name: Docker Tests (Quick)
    needs: build-and-push-image
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]

      # Restore test data cache (separate from save to ensure cache is saved even if tests fail)
      - name: Restore test data cache
        id: cache-test-data-restore
        uses: actions/cache/restore@v4
        with:
          path: tests/data
          key: test-data-${{ hashFiles('tests/test_data_config.json') }}
          restore-keys: |
            test-data-

      # Download test data if not cached using wget (more reliable for large files)
      - name: Download test data
        if: steps.cache-test-data-restore.outputs.cache-hit != 'true'
        run: |
          echo "Downloading test data (1.1GB archive from Zenodo)..."
          echo "This may take 30-90 minutes depending on Zenodo server load"

          # Use wget with retry and continue capabilities
          # -c: continue partial downloads
          # --tries=5: retry up to 5 times
          # --timeout=60: 60s timeout for connections
          # --progress=dot:giga: show progress
          mkdir -p /tmp/vntyper-download
          wget -c --tries=5 --timeout=60 --progress=dot:giga \
            -O /tmp/vntyper-download/data.zip \
            "https://zenodo.org/records/17377082/files/data.zip?download=1" || exit 1

          echo "Extracting archive..."
          mkdir -p tests/data
          unzip -q /tmp/vntyper-download/data.zip -d tests/data

          echo "Verifying download..."
          python3 -c "
          import json
          from tests.test_data_utils import compute_md5
          from pathlib import Path

          # Just verify key files exist
          key_files = [
              'tests/data/example_b178_hg19_subset.bam',
              'tests/data/example_b178_hg19_subset.bam.bai',
          ]

          for f in key_files:
              p = Path(f)
              if not p.exists():
                  raise FileNotFoundError(f'Missing file: {f}')
              print(f'✓ Verified: {f} ({p.stat().st_size / (1024*1024):.1f} MB)')

          print('✓ Test data download and extraction complete')
          "

          # Cleanup
          rm -rf /tmp/vntyper-download
        timeout-minutes: 120

      # Save test data cache (runs even if tests fail, ensuring cache is available for next run)
      - name: Save test data cache
        uses: actions/cache/save@v4
        if: always() && steps.cache-test-data-restore.outputs.cache-hit != 'true'
        with:
          path: tests/data
          key: test-data-${{ hashFiles('tests/test_data_config.json') }}

      - name: Run Docker quick tests
        run: make test-docker-quick
        timeout-minutes: 20

      - name: Display test summary
        if: always()
        run: |
          echo "✓ Docker quick tests completed"

  # Docker Full Test Suite - Run only on main branch
  test-docker-full:
    name: Docker Tests (Full Suite)
    needs: [build-and-push-image, test-docker-quick]
    runs-on: ubuntu-latest
    # Only run full suite on main branch or manual trigger
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .[dev]

      # Restore test data cache (separate from save to ensure cache is saved even if tests fail)
      - name: Restore test data cache
        id: cache-test-data-full-restore
        uses: actions/cache/restore@v4
        with:
          path: tests/data
          key: test-data-${{ hashFiles('tests/test_data_config.json') }}
          restore-keys: |
            test-data-

      # Download test data if not cached using wget (more reliable for large files)
      - name: Download test data
        if: steps.cache-test-data-full-restore.outputs.cache-hit != 'true'
        run: |
          echo "Downloading test data (1.1GB archive from Zenodo)..."
          echo "This may take 30-90 minutes depending on Zenodo server load"

          # Use wget with retry and continue capabilities
          mkdir -p /tmp/vntyper-download
          wget -c --tries=5 --timeout=60 --progress=dot:giga \
            -O /tmp/vntyper-download/data.zip \
            "https://zenodo.org/records/17377082/files/data.zip?download=1" || exit 1

          echo "Extracting archive..."
          mkdir -p tests/data
          unzip -q /tmp/vntyper-download/data.zip -d tests/data

          echo "Verifying download..."
          python3 -c "
          import json
          from tests.test_data_utils import compute_md5
          from pathlib import Path

          # Verify all key test files exist
          with open('tests/test_data_config.json') as f:
              config = json.load(f)

          verified = 0
          for resource in config.get('file_resources', [])[:5]:  # Check first 5 files
              p = Path(resource['local_path']) / resource['filename']
              if not p.exists():
                  raise FileNotFoundError(f'Missing file: {p}')
              verified += 1

          print(f'✓ Verified {verified} test files')
          print('✓ Test data download and extraction complete')
          "

          # Cleanup
          rm -rf /tmp/vntyper-download
        timeout-minutes: 120

      # Save test data cache (runs even if tests fail, ensuring cache is available for next run)
      - name: Save test data cache
        uses: actions/cache/save@v4
        if: always() && steps.cache-test-data-full-restore.outputs.cache-hit != 'true'
        with:
          path: tests/data
          key: test-data-${{ hashFiles('tests/test_data_config.json') }}

      - name: Run full Docker test suite
        run: make test-docker
        timeout-minutes: 60

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: docker-test-results-${{ github.run_id }}
          path: |
            pytest-results/
            htmlcov/
          retention-days: 30
